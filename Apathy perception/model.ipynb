{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "historic-session",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing required libraries:\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "first-wheel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting the path to our eye dataset: \n",
    "Directory = r\"C:\\Users\\saich\\Desktop\\major\\Apathy perception\\dataset_new\\train\"\n",
    "# specify two categories on which we want to train our data:\n",
    "CATEGORIES = ['Closed' , 'Open']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "level-spine",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting image size:\n",
    "img_size = 24\n",
    "data = []\n",
    "\n",
    "#iterating over each image and get the image in array form,\n",
    "for category in CATEGORIES:\n",
    "    folder = os.path.join(Directory,category)\n",
    "    label = CATEGORIES.index(category)\n",
    "    for img in os.listdir(folder):\n",
    "        img_path = os.path.join(folder, img)\n",
    "        img_arr = cv2.imread(img_path)\n",
    "        img_arr = cv2.cvtColor(img_arr, cv2.COLOR_BGR2GRAY)\n",
    "        img_arr = cv2.resize(img_arr,(img_size, img_size),1)\n",
    "        data.append([img_arr , label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ready-drove",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1234"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see the length of data:\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "japanese-reference",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we shuffle the data to get random images of open eyes and closed eyes:\n",
    "random.shuffle(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cognitive-purple",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dividing features and label for training the model: \n",
    "X = []\n",
    "Y = []\n",
    "\n",
    "for features,label in data:\n",
    "    X.append(features)\n",
    "    Y.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "answering-steel",
   "metadata": {},
   "outputs": [],
   "source": [
    "#covert them into array:\n",
    "X = np.array(X)\n",
    "Y = np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "headed-addiction",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the data into system:\n",
    "pickle.dump(X , open('X.pkl' , 'wb'))\n",
    "pickle.dump(Y , open('Y.pkl' , 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "pretty-constitution",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the image array:\n",
    "X = X/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "scheduled-silver",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.62745098, 0.63137255, 0.63529412, ..., 0.65882353,\n",
       "         0.65490196, 0.64705882],\n",
       "        [0.59607843, 0.61176471, 0.6       , ..., 0.61176471,\n",
       "         0.62352941, 0.60392157],\n",
       "        [0.56078431, 0.56862745, 0.56470588, ..., 0.55294118,\n",
       "         0.57647059, 0.56862745],\n",
       "        ...,\n",
       "        [0.72156863, 0.72156863, 0.71764706, ..., 0.69019608,\n",
       "         0.71372549, 0.71764706],\n",
       "        [0.72941176, 0.72941176, 0.73333333, ..., 0.70196078,\n",
       "         0.70980392, 0.71372549],\n",
       "        [0.72941176, 0.72156863, 0.7372549 , ..., 0.70196078,\n",
       "         0.71372549, 0.70196078]],\n",
       "\n",
       "       [[0.43529412, 0.4745098 , 0.47843137, ..., 0.65490196,\n",
       "         0.63921569, 0.6627451 ],\n",
       "        [0.45098039, 0.47058824, 0.4745098 , ..., 0.65490196,\n",
       "         0.65098039, 0.65098039],\n",
       "        [0.43529412, 0.43921569, 0.48627451, ..., 0.6627451 ,\n",
       "         0.64705882, 0.64705882],\n",
       "        ...,\n",
       "        [0.54117647, 0.56862745, 0.56470588, ..., 0.52941176,\n",
       "         0.51372549, 0.51372549],\n",
       "        [0.55686275, 0.56078431, 0.57647059, ..., 0.51764706,\n",
       "         0.51764706, 0.50588235],\n",
       "        [0.56862745, 0.57254902, 0.57647059, ..., 0.50196078,\n",
       "         0.50980392, 0.48235294]],\n",
       "\n",
       "       [[0.89019608, 0.89803922, 0.90196078, ..., 0.9372549 ,\n",
       "         0.93333333, 0.9254902 ],\n",
       "        [0.89411765, 0.89803922, 0.90196078, ..., 0.92941176,\n",
       "         0.91764706, 0.90196078],\n",
       "        [0.89411765, 0.89803922, 0.89803922, ..., 0.88627451,\n",
       "         0.88235294, 0.88627451],\n",
       "        ...,\n",
       "        [0.92156863, 0.9372549 , 0.94117647, ..., 0.9372549 ,\n",
       "         0.95294118, 0.95294118],\n",
       "        [0.93333333, 0.93333333, 0.94509804, ..., 0.94901961,\n",
       "         0.96078431, 0.95294118],\n",
       "        [0.9254902 , 0.93333333, 0.95294118, ..., 0.97254902,\n",
       "         0.95294118, 0.93333333]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.39607843, 0.37254902, 0.38039216, ..., 0.55294118,\n",
       "         0.54509804, 0.54117647],\n",
       "        [0.43529412, 0.42745098, 0.4       , ..., 0.49803922,\n",
       "         0.50588235, 0.52156863],\n",
       "        [0.43921569, 0.42352941, 0.4       , ..., 0.39215686,\n",
       "         0.41568627, 0.43921569],\n",
       "        ...,\n",
       "        [0.58823529, 0.60392157, 0.61568627, ..., 0.6       ,\n",
       "         0.60392157, 0.59607843],\n",
       "        [0.59607843, 0.60392157, 0.61568627, ..., 0.56862745,\n",
       "         0.56470588, 0.56470588],\n",
       "        [0.58823529, 0.59607843, 0.61176471, ..., 0.55294118,\n",
       "         0.53333333, 0.5372549 ]],\n",
       "\n",
       "       [[0.16862745, 0.18039216, 0.18039216, ..., 0.33333333,\n",
       "         0.34509804, 0.34509804],\n",
       "        [0.17647059, 0.18431373, 0.20392157, ..., 0.35686275,\n",
       "         0.34901961, 0.34901961],\n",
       "        [0.18039216, 0.18431373, 0.20392157, ..., 0.36470588,\n",
       "         0.36078431, 0.36862745],\n",
       "        ...,\n",
       "        [0.35686275, 0.36078431, 0.34901961, ..., 0.2745098 ,\n",
       "         0.28627451, 0.29019608],\n",
       "        [0.35294118, 0.35686275, 0.36078431, ..., 0.29019608,\n",
       "         0.29019608, 0.31372549],\n",
       "        [0.35294118, 0.36470588, 0.36470588, ..., 0.28627451,\n",
       "         0.29019608, 0.32156863]],\n",
       "\n",
       "       [[0.12156863, 0.10980392, 0.10196078, ..., 0.24705882,\n",
       "         0.23529412, 0.26666667],\n",
       "        [0.14509804, 0.15294118, 0.1372549 , ..., 0.23529412,\n",
       "         0.21176471, 0.24705882],\n",
       "        [0.20392157, 0.18823529, 0.21176471, ..., 0.22352941,\n",
       "         0.21960784, 0.25098039],\n",
       "        ...,\n",
       "        [0.57647059, 0.45882353, 0.4       , ..., 0.29019608,\n",
       "         0.29411765, 0.2627451 ],\n",
       "        [0.54901961, 0.45098039, 0.41568627, ..., 0.30588235,\n",
       "         0.29019608, 0.27843137],\n",
       "        [0.54509804, 0.45882353, 0.41568627, ..., 0.29803922,\n",
       "         0.29411765, 0.29019608]]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "current-pasta",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1234, 24, 24, 1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reshape the X array to (24,24,1)\n",
    "img_rows,img_cols = 24,24\n",
    "X = X.reshape(X.shape[0],img_rows,img_cols,1)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "inner-greensboro",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will be using keras to create the model:\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D , MaxPooling2D , Flatten , Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "soviet-hamilton",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating model:\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(64 , (3,3) , activation = 'relu' , input_shape= X.shape[1:]))\n",
    "model.add(MaxPooling2D((1,1)))\n",
    "\n",
    "model.add(Conv2D(64 , (3,3) , activation = 'relu'))\n",
    "model.add(MaxPooling2D((1,1)))\n",
    "\n",
    "model.add(Conv2D(64 , (3,3) , activation = 'relu'))\n",
    "model.add(MaxPooling2D((1,1)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(128, activation = 'relu'))\n",
    "\n",
    "model.add(Dense(2\n",
    ", activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "seven-definition",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model that we have created\n",
    "model.compile(optimizer = 'adam' , loss = 'sparse_categorical_crossentropy' , metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "nasty-measurement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "35/35 [==============================] - 8s 174ms/step - loss: 0.4988 - accuracy: 0.7351 - val_loss: 0.2004 - val_accuracy: 0.9194\n",
      "Epoch 2/5\n",
      "35/35 [==============================] - 7s 186ms/step - loss: 0.1852 - accuracy: 0.9252 - val_loss: 0.2334 - val_accuracy: 0.9274\n",
      "Epoch 3/5\n",
      "35/35 [==============================] - 6s 183ms/step - loss: 0.1327 - accuracy: 0.9477 - val_loss: 0.1381 - val_accuracy: 0.9839\n",
      "Epoch 4/5\n",
      "35/35 [==============================] - 6s 172ms/step - loss: 0.0990 - accuracy: 0.9604 - val_loss: 0.2221 - val_accuracy: 0.9355\n",
      "Epoch 5/5\n",
      "35/35 [==============================] - 6s 174ms/step - loss: 0.1076 - accuracy: 0.9622 - val_loss: 0.0890 - val_accuracy: 0.9597\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1907d6d05b0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit X , Y to the model to see accuracy of model:\n",
    "model.fit(X, Y, epochs = 5 , validation_split = 0.1 , batch_size = 32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "engaged-exclusive",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "purple-worry",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model and architecture to single file\n",
    "model.save(\"custmodel.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "fef42c53574945e788519e3fcad370e68d9e1842cb0342f09b1ce9ef5e2f6a97"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
